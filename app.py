import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np
import cv2
import io
from fpdf import FPDF
import datetime

# --- 1. MODEL SETUP ---
@st.cache_resource
def load_all():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = models.resnet18()
    model.fc = nn.Linear(model.fc.in_features, 2)
    model.load_state_dict(torch.load('skin_model.pth', map_location=device))
    model.to(device).eval()
    return model, device

model, device = load_all()

# --- 2. GRAD-CAM & DETECTION ENGINES ---
class GradCAM:
    def __init__(self, model, target_layer):
        self.model, self.target_layer = model, target_layer
        self.gradients, self.activations = None, None
        def save_gradient(module, grad_input, grad_output): self.gradients = grad_output[0]
        def save_activation(module, input, output): self.activations = output
        self.target_layer.register_forward_hook(save_activation)
        self.target_layer.register_full_backward_hook(save_gradient)

    def generate(self, input_tensor, class_idx):
        output = self.model(input_tensor)
        self.model.zero_grad()
        output[0, class_idx].backward()
        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        cam = torch.sum(weights * self.activations, dim=1).squeeze().detach().cpu().numpy()
        cam = np.maximum(cam, 0)
        cam = cv2.resize(cam, (224, 224))
        return (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)

def detect_moles(image_pil):
    img = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    moles = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        if w > 25 and h > 25: # Filtering noise
            padding = 15
            crop = img[max(0, y-padding):y+h+padding, max(0, x-padding):x+w+padding]
            moles.append({'img': crop, 'box': (x, y, w, h)})
    return moles

# --- 3. PDF GENERATOR ---
def create_pdf_report(result, confidence, original_img, heatmap_img):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("helvetica", 'B', 20)
    pdf.cell(0, 10, text="Medical AI Analysis Report", align='C', new_x="LMARGIN", new_y="NEXT")
    pdf.set_font("helvetica", size=10)
    pdf.cell(0, 10, text=f"Date: {datetime.date.today()}", align='C', new_x="LMARGIN", new_y="NEXT")
    pdf.ln(10)
    
    pdf.set_font("helvetica", 'B', 14)
    pdf.cell(0, 10, text="1. Analysis Results", new_x="LMARGIN", new_y="NEXT")
    pdf.set_font("helvetica", size=12)
    pdf.cell(0, 10, text=f"Detected Category: {result}", new_x="LMARGIN", new_y="NEXT")
    pdf.cell(0, 10, text=f"AI Confidence Score: {confidence:.2f}%", new_x="LMARGIN", new_y="NEXT")
    
    original_img.save("temp_orig.png")
    heatmap_img.save("temp_heat.png")
    pdf.image("temp_orig.png", x=10, y=80, w=90)
    pdf.image("temp_heat.png", x=110, y=80, w=90)
    
    pdf.set_y(-30)
    pdf.set_font("helvetica", 'I', 8)
    pdf.multi_cell(0, 5, text="DISCLAIMER: This report is generated by an AI model for informational use only. Consult a dermatologist for medical diagnosis.")
    return bytes(pdf.output())

# --- 4. APP UI ---
st.set_page_config(page_title="Skin AI Pro", layout="wide")
st.title("üî¨ Advanced Dermatological AI")

if 'analysis_done' not in st.session_state: st.session_state.analysis_done = False

uploaded_file = st.file_uploader("Upload Skin Image", type=["jpg", "png", "jpeg"])

if uploaded_file:
    image = Image.open(uploaded_file).convert('RGB')
    tab1, tab2 = st.tabs(["Single Analysis & PDF", "Multi-Spot Detection"])

    with tab1:
        col1, col2 = st.columns(2)
        with col1:
            st.image(image, caption="Original Image", width="stretch")
            if st.button("üöÄ Run AI Analysis"):
                transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
                img_tensor = transform(image).unsqueeze(0).to(device)
                img_tensor.requires_grad = True
                
                output = model(img_tensor)
                conf, pred = torch.max(torch.nn.functional.softmax(output, dim=1), 1)
                
                cam_engine = GradCAM(model, model.layer4[1].conv2)
                mask = cam_engine.generate(img_tensor, pred.item())
                heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)
                overlay = cv2.addWeighted(np.array(image.resize((224, 224))), 0.6, cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB), 0.4, 0)
                
                st.session_state.res_text = ['Melanoma', 'NotMelanoma'][pred.item()]
                st.session_state.confidence = conf.item()*100
                st.session_state.overlay_pil = Image.fromarray(overlay)
                st.session_state.analysis_done = True

        if st.session_state.analysis_done:
            with col2:
                st.image(st.session_state.overlay_pil, caption="AI Focus Area", width="stretch")
                st.success(f"Result: {st.session_state.res_text}")
                pdf_bytes = create_pdf_report(st.session_state.res_text, st.session_state.confidence, image.resize((224, 224)), st.session_state.overlay_pil)
                st.download_button("üì• Download PDF Report", pdf_bytes, "report.pdf", "application/pdf")

    with tab2:
        st.write("Detect and classify multiple spots in a single photo.")
        if st.button("üîç Detect All Spots"):
            moles = detect_moles(image)
            st.write(f"Found {len(moles)} spots.")
            for i, m in enumerate(moles):
                crop_pil = Image.fromarray(cv2.cvtColor(m['img'], cv2.COLOR_BGR2RGB))
                t = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
                with torch.no_grad():
                    out = model(t(crop_pil).unsqueeze(0).to(device))
                    res = ['Melanoma', 'NotMelanoma'][torch.max(out, 1)[1].item()]
                
                # FIXED BLOCK: Standard multi-line if/else to avoid "Magic" errors
                c1, c2 = st.columns([1, 4])
                with c1:
                    st.image(crop_pil, width=100)
                with c2:
                    if res == 'Melanoma':
                        st.error(f"Spot {i+1}: {res}")
                    else:
                        st.info(f"Spot {i+1}: {res}")